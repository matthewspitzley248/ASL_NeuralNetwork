# import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from random import randint
from random import seed
from random import random
from shutil import copyfile
from skimage.transform import resize

from keras.src.callbacks import ReduceLROnPlateau
from keras.src.layers import BatchNormalization, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import tensorflow as tf

import os
from os import listdir

from tensorflow.python.keras import regularizers
from tensorflow.python.keras.engine.input_layer import InputLayer
from tensorflow.python.keras.layers.pooling import MaxPooling2D

print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

# set global values
datasetdir = "asl_dataset/new_asl_dataset/train/"
dataset_home = 'asl_dataset/Data/'
subdirs = ['train/', 'test/']
labeldirs = [#'0/', '1/', '2/', '3/', '4/', '5/', '6/', '7/', '8/', '9/',
             'a/', 'b/', 'c/', 'd/', 'e/', 'f/', 'g/', 'h/', 'i/', 'j/', 'k/',
             'l/', 'm/', 'n/', 'o/', 'p/', 'q/', 'r/', 's/', 't/', 'u/', 'v/',
             'w/', 'x/', 'y/', 'z/', 'Blank/']
# shape for the iamges to be normalized to
#new_img_shape = (200, 200, 3)

def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]


def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))
        yield (batch_crops, batch_y)

def array_to_labels(array, label_to_class):
    labels = []
    for onehot_array in array:
        idx = np.where(onehot_array == 1)[0]
        labels.append([label_to_class[i] for i in idx][0])
    return labels

def infoOnDataset():

    #gets number of images in each dir
    listCount = []
    i = 0;
    for imageType in os.listdir(datasetdir):
        listCount.append(0)
        for image in os.listdir(datasetdir+imageType):
            listCount[i] += 1
        i+=1

    plt.grid(False)
    plt.xticks(range(len(labeldirs)), labeldirs)
    #plt.yticks([])
    thisplot = plt.bar(range(len(labeldirs)), listCount, color="#777777")
    plt.show()


def seperateImages():
    for subdir in subdirs:
        for labldir in labeldirs:
            newdir = dataset_home + subdir + labldir
            os.makedirs(newdir, exist_ok=True)

    # seed random number generator
    seed()
    # define ratio of pictures to use for validation
    val_ratio = 0.20
    # copy training dataset images into subdirectories
    for src_directory in labeldirs:
        # src_directory = ''
        for file in os.listdir(datasetdir + src_directory):
            src = datasetdir + src_directory + '/' + file
            dst_dir = 'train/'
            if random() < val_ratio:
                dst_dir = 'test/'

            # grabs the letter or number from the photo name
            #photoValue = file[6]
            dst = dataset_home + dst_dir + src_directory + '/' + file
            copyfile(src, dst)

            '''
            if file.startswith('hand1_0'):  # used to identify
                dst = dataset_home + dst_dir + '0/' + file
                copyfile(src, dst)
            elif file.startswith('hand1_1'):  # used to identify
                dst = dataset_home + dst_dir + '1/' + file
                copyfile(src, dst)
            '''


def normalizeImages(batch_size, file, shuffle, new_img_shape, rotation, zoom, shift):
    # expand our training dataset -- randomly transform the image datasets
    image_gen = ImageDataGenerator(rescale=1.0 / 255.0,  # scales image between 0 and 1
                                   rotation_range=rotation,  # randomly rotate images in the range (degrees, 0 to 180)
                                   zoom_range=zoom,  # Randomly zoom image
                                   horizontal_flip=True,
                                   width_shift_range=shift,   # randomly shift images horizontally (fraction of total width)
                                   height_shift_range=shift)  # randomly shift images vertically (fraction of total height)
                                   #preprocessing_function = random_crop)

    # no shuffle at test images
    image_gen = image_gen.flow_from_directory(dataset_home + '/' + file + '/',
                                              target_size=new_img_shape[:2],
                                              color_mode='rgb',
                                              batch_size=batch_size,
                                              class_mode='categorical',
                                              shuffle=shuffle
                                              )

    #image_gen = crop_generator(image_gen, new_img_shape[0]-new_img_shape[0]*.75)

    # check class labels
    print(image_gen.class_indices)

    # Get a sample of the training data batch
    images, labels = image_gen.next()  # get the 'next' batch of images/labels
    print(len(images))
    print(len(labels))
    # lengths should be the batch size

    # Get the first image and its shape
    print(images[0].shape)

    # pixel value should be between 0~1, the shape should be 200x200x3
    # -- decided by the ImageDataGenerator class
    return (image_gen)


# visualizes the images
def show_images(images, labels, labelInfo, num):
    """
  Displays 25 images from a data batch.
  """
    label_to_class = {v: k for k, v in labelInfo.items()}
    # Setup the figure
    plt.figure(figsize=(10, 10))
    # Loop through 25 (for displaying 25 images)
    for i in range(num):
        # Create subplots (5 rows, 5 columns)
        ax = plt.subplot(5, 5, i + 1)
        # Display an image
        plt.imshow(images[i])
        plt.title(labels[i])#array_to_labels(labels[i], label_to_class))
        plt.axis("off")
    plt.show()


def createModel(filename, train_image_gen, test_image_gen, new_img_shape, modelName, epochs):
    # Make the creating of our model a little easier
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation
    from tensorflow.keras import Sequential

    # https://stats.stackexchange.com/questions/148139/rules-for-selecting-convolutional-neural-network-hyperparameters

    # model = Sequential()
    # # input layer
    # # Block 1
    # model.add(Conv2D(32, 3, activation='relu', padding='same', input_shape=new_img_shape))
    # model.add(Conv2D(32, 3, activation='relu', padding='same'))
    # #model.add(BatchNormalization())
    # model.add(MaxPool2D(padding='same'))
    # model.add(Dropout(0.2))
    #
    # # Block 2
    # model.add(Conv2D(64, 3, activation='relu', padding='same'))
    # model.add(Conv2D(64, 3, activation='relu', padding='same'))
    # #model.add(BatchNormalization())
    # model.add(MaxPool2D(padding='same'))
    # model.add(Dropout(0.2))
    #
    # # Block 3
    # model.add(Conv2D(128, 3, activation='relu', padding='same'))
    # model.add(Conv2D(128, 3, activation='relu', padding='same'))
    # #model.add(BatchNormalization())
    # model.add(MaxPool2D(padding='same'))
    # model.add(Dropout(0.3))
    #
    # # Block 4
    # model.add(Conv2D(256, 3, activation='relu', padding='same'))
    # model.add(Conv2D(256, 3, activation='relu', padding='same'))
    # # model.add(BatchNormalization())
    # model.add(MaxPool2D(padding='same'))
    # model.add(Dropout(0.3))
    #
    # # Block 5
    # model.add(Conv2D(512, 3, activation='relu', padding='same'))
    # model.add(Conv2D(512, 3, activation='relu', padding='same'))
    # # model.add(BatchNormalization())
    # model.add(MaxPool2D(padding='same'))
    # model.add(Dropout(0.4))
    #
    # # fully connected layer
    # model.add(Flatten())
    #
    # model.add(Dense(2048, activation='relu'))
    # model.add(Dropout(0.1))
    # model.add(Dense(512, activation='relu'))
    # model.add(Dropout(0.2))
    # model.add(Dense(128, activation='relu'))
    # model.add(Dropout(0.3))
    #
    # # output layer
    # model.add(Dense(27, activation='softmax'))
    # model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])



    # Define the CNN model
    # model = Sequential()
    #
    # # Convolutional layers
    # model.add(Conv2D(32, (3, 3), activation='relu', input_shape=new_img_shape))
    # model.add(MaxPool2D((2, 2)))
    # model.add(Dropout(0.1))
    #
    # model.add(Conv2D(64, (3, 3), activation='relu'))
    # model.add(MaxPool2D((2, 2)))
    # model.add(Dropout(0.2))
    #
    # model.add(Conv2D(128, (3, 3), activation='relu'))
    # model.add(MaxPool2D((2, 2)))
    # model.add(Dropout(0.3))
    #
    # model.add(Conv2D(256, (3, 3), activation='relu'))
    # model.add(MaxPool2D((2, 2)))
    # model.add(Dropout(0.4))
    #
    # model.add(Conv2D(512, (3, 3), activation='relu'))
    # model.add(MaxPool2D((2, 2)))
    # model.add(Dropout(0.4))
    #
    # # Flatten layer to transition from convolutional to dense layers
    # model.add(Flatten())
    #
    # # Dense layers
    # model.add(Dense(512, activation='relu'))
    # model.add(BatchNormalization())  # Batch Normalization
    #
    # # Regularization - Dropout
    # model.add(Dropout(0.5))
    #
    # # Output layer
    # num_classes = 27  # Assuming 27 classes
    # model.add(Dense(num_classes, activation='softmax',
    #                        kernel_regularizer=tf.keras.regularizers.l2(0.01)))  # Regularization - L2
    #
    # # Compile the model
    # model.compile(optimizer='adam',
    #               loss='categorical_crossentropy',
    #               metrics=['accuracy'])



    # building a linear stack of layers with the sequential model
    # build a sequential model
    model = Sequential()
    #model.add(InputLayer(input_shape=new_img_shape))

    # 1st conv block
    model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same', input_shape=new_img_shape))
    model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))
    model.add(MaxPool2D(pool_size=(2, 2), padding='same'))
    # 2nd conv block
    model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))
    model.add(MaxPool2D(pool_size=(2, 2), padding='same'))
    model.add(BatchNormalization())
    # 3rd conv block
    model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))
    model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))
    model.add(BatchNormalization())
    # ANN block
    model.add(Flatten())
    model.add(Dense(units=100, activation='relu'))
    model.add(Dense(units=100, activation='relu'))
    model.add(Dropout(0.25))
    # output layer
    model.add(Dense(27, activation='softmax'))

    # compiling the sequential model
    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')

    print(model.summary())

    # base_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    # Note that, Since we're working on a binary classification problem (dogs vs. cats),
    # the loss function we're using is 'binary_crossentropy',
    # if it was mult-iclass, we might use something like 'categorical_crossentropy'.

    from tensorflow.keras.callbacks import EarlyStopping
    early_stopping = EarlyStopping(monitor='val_loss',
                                  min_delta=0.001,
                                  patience=5,
                                  restore_best_weights=True,
                                  verbose=1)

    reduce_learning_rate = ReduceLROnPlateau(monitor='val_accuracy',
                                             patience=2,
                                             factor=0.5,
                                             verbose=1)
    # fit the model

    if(modelName != ''):
        model = tf.keras.models.load_model('Models/'+modelName)
        print('------------------------------Loading Model------------------------------')


    base_model_history = model.fit(train_image_gen,
                                   epochs=epochs,
                                   validation_data=test_image_gen,
                                   callbacks=[early_stopping,reduce_learning_rate],
                                   verbose=1)

    print(model.summary())

    # Saving and reloading a model
    '''After training a model, it's a good idea to save it.
    Saving it means you can share it with colleagues,put it in an application and more importantly,
    won't have to go through the potentially expensive step of retraining it.

    Even on a GPU, our full model took a while to train. So it's a good idea to save it.
    '''
    from tensorflow.keras.models import load_model
    model.save(filename)

    train_acc = base_model_history.history['accuracy']
    epochs = [i for i in range(len(train_acc))]
    fig, ax = plt.subplots(1, 2)
    #train_acc = base_model_history.history['accuracy']
    train_loss = base_model_history.history['loss']
    val_acc = base_model_history.history['val_accuracy']
    val_loss = base_model_history.history['val_loss']
    fig.set_size_inches(16, 9)

    ax[0].plot(epochs, train_acc, 'go-', label='Training Accuracy')
    ax[0].plot(epochs, val_acc, 'ro-', label='Testing Accuracy')
    ax[0].set_title('Training & Validation Accuracy')
    ax[0].legend()
    ax[0].set_xlabel("Epochs")
    ax[0].set_ylabel("Accuracy")

    ax[1].plot(epochs, train_loss, 'g-o', label='Training Loss')
    ax[1].plot(epochs, val_loss, 'r-o', label='Testing Loss')
    ax[1].set_title('Testing Accuracy & Loss')
    ax[1].legend()
    ax[1].set_xlabel("Epochs")
    ax[1].set_ylabel("Loss")
    plt.show()


# importDataset()
# seperateImages()

def GenModel(modelRef, epochs, batchSize):

    new_img_shape = (300, 300, 3)

    train_image_gen = normalizeImages(batchSize, 'train', True, new_img_shape, 20, [0.65, 1.35], 0.2)
    test_image_gen = normalizeImages(batchSize, 'test', True, new_img_shape, 20, [0.65, 1.35], 0.2)

    images, labels = train_image_gen.next()  # get the 'next' batch of images/labels
    labelInfo = test_image_gen.class_indices
    label_to_class = {v: k for k, v in labelInfo.items()}
    img_labels = array_to_labels(labels, label_to_class)
    # not working right
    show_images(images, img_labels, labelInfo, 25)

    modelDir = 'Models/'

    largeNum = 0
    for file in os.listdir(modelDir):
        if (int(file[5:file.index('.keras')]) > largeNum):
            largeNum = int(file[5:file.index('.')])

    modelName = 'Model' + str(largeNum + 1) + '.keras'
    print(modelName)

    createModel(modelDir + modelName, train_image_gen, test_image_gen, new_img_shape, modelRef, epochs)